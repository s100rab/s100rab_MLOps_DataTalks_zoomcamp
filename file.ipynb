{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üöÄ Proof of Concept: Real-Time Data Monitoring with Evidently AI and MLOps üöÄ\n",
    "\n",
    "I recently completed a proof of concept project that integrates several powerful tools to monitor and evaluate machine learning systems in real-time. This project leverages the capabilities of Evidently AI, Grafana, and PostgreSQL, packaged neatly in Docker containers.\n",
    "\n",
    "üîó GitHub Repository: [s100rab_MLOps_DataTalks_zoomcamp](https://github.com/s100rab/s100rab_MLOps_DataTalks_zoomcamp/tree/main/05-monitoring)\n",
    "\n",
    "### Project Scope and Technology Stack:\n",
    "- Evidently AI: For generating reports, test suites, and dashboards that evaluate and monitor data and ML models.\n",
    "- Grafana: For visualizing metrics and creating interactive dashboards.\n",
    "- PostgreSQL: To store metrics data.\n",
    "- Docker: To containerize and orchestrate the services for seamless deployment and management.\n",
    "\n",
    "### Challenges Faced:\n",
    "1. Interpreting Requirements: Initially struggled with understanding the requirements for expanded monitoring and quantile metrics.\n",
    "2. Integration Complexity: Ensuring seamless integration of Evidently AI reports with Grafana dashboards and PostgreSQL.\n",
    "3. Dashboard Customization: Customizing and saving dashboard configurations without overwriting existing panels.\n",
    "4. Data Management: Efficiently managing and querying large datasets to monitor metrics daily.\n",
    "\n",
    "### Solutions and Approach:\n",
    "- Expanded Monitoring: Using Evidently AI‚Äôs `ColumnQuantileMetric` to calculate daily quantile values for fare amounts.\n",
    "- Separate Configurations: Avoiding overwriting by creating separate database tables and Grafana panels for homework.\n",
    "- Efficient Queries: Streamlining SQL queries for Grafana dashboards by copying and editing existing queries.\n",
    "- Automated Workflows: Setting up automated scripts to run daily data monitoring and update dashboards.\n",
    "\n",
    "### Applications in Real-Time Scenarios:\n",
    "This project showcases the potential for real-time monitoring and evaluation in various ML-powered systems:\n",
    "- Ride-Sharing Platforms: Monitoring trip fare distributions and identifying anomalies in real-time.\n",
    "- Financial Systems: Real-time monitoring of transaction amounts to detect fraud or unusual activity.\n",
    "- Healthcare: Monitoring patient data metrics to ensure consistent and accurate data collection and processing.\n",
    "\n",
    "### Learnings and Next Steps:\n",
    "Understanding Evidently AI has been a game-changer:\n",
    "1. Reports: Inline in Jupyter notebooks and exportable to JSON, HTML, etc.\n",
    "2. Test Suites: Pre-defined presets for common metrics.\n",
    "3. Dashboards: Customizable panels and integration with external solutions like Prometheus and Grafana.\n",
    "\n",
    "Moving forward, there's still so much to explore in the realm of MLOps and Evidently AI. On to the next module!\n",
    "\n",
    "üí° Key Takeaways:\n",
    "- Evidently AI simplifies the evaluation and monitoring of data and ML models.\n",
    "- Effective integration of monitoring tools can provide powerful real-time insights.\n",
    "- Properly organizing and managing configurations and data is crucial for scalable solutions.\n",
    "\n",
    "Check out the detailed implementation and source code on my GitHub: [s100rab_MLOps_DataTalks_zoomcamp](https://github.com/s100rab/s100rab_MLOps_DataTalks_zoomcamp/tree/main/05-monitoring)\n",
    "\n",
    "#MLOps #DataScience #MachineLearning #EvidentlyAI #Grafana #PostgreSQL #Docker #RealTimeMonitoring #DataTalksClub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sure! Here's a LinkedIn-style post about your proof of concept project, highlighting the technology stack, challenges faced, project scope, and real-time applications:\n",
    "\n",
    "---\n",
    "\n",
    "üöÄ Project Highlight: Proof of Concept with Best Practices in MLOps üöÄ\n",
    "\n",
    "I'm thrilled to share a recent proof of concept I was working on, leveraging a comprehensive technology stack to enhance our MLOps practices. Here's a deep dive into the project, the challenges we encountered, and the real-world applications we envisioned.\n",
    "\n",
    "### üîß Technology Stack:\n",
    "1. Python & Pytest: For unit and integration testing to ensure code reliability.\n",
    "2. Docker & Docker-Compose: For containerization and managing multi-service applications.\n",
    "3. LocalStack: To emulate AWS cloud services locally for testing.\n",
    "4. Terraform: For Infrastructure-as-Code (IaC), setting up AWS resources like Kinesis Streams, Lambda, S3, and ECR.\n",
    "5. GitHub Actions: Automating CI/CD pipelines to build, test, and deploy services to AWS Lambda.\n",
    "6. PostgreSQL & Adminer: For managing and visualizing database metrics.\n",
    "7. Grafana: For creating detailed dashboards to monitor metrics.\n",
    "8. Makefile: For automating tasks and simplifying commands.\n",
    "9. Git Pre-Commit Hooks: Ensuring code quality with linting and formatting checks.\n",
    "\n",
    "### üîç Project Scope:\n",
    "The goal was to set up a stream-based pipeline infrastructure in AWS using Terraform, ensuring the entire setup could be managed as code. Key components included:\n",
    "- Kinesis Streams: For data ingestion (Producer & Consumer).\n",
    "- AWS Lambda: Serving API endpoints.\n",
    "- S3 Buckets: Storing model artifacts.\n",
    "- ECR: Container image registry.\n",
    "\n",
    "### üåü Challenges Faced:\n",
    "1. Interpreting Requirements: Understanding terms like \"expanded monitoring\" and adapting the existing data framework for new datasets.\n",
    "2. Setting Up LocalStack: Configuring LocalStack to accurately mimic AWS services and ensuring seamless integration with our code.\n",
    "3. Testing Integration: Writing integration tests that interact with emulated S3 buckets and verifying data integrity.\n",
    "4. Grafana Dashboards: Customizing queries and panels to visualize data effectively without overwriting existing configurations.\n",
    "5. CI/CD Workflows: Creating robust workflows in GitHub Actions for continuous integration and delivery, managing dependencies, and automating deployments.\n",
    "\n",
    "### üìà Real-Time Applications:\n",
    "- Predictive Analytics: Implementing a ride duration prediction model, which could be extended to other real-time prediction scenarios.\n",
    "- Data Monitoring: Using Grafana to monitor and visualize real-time data metrics, ensuring operational efficiency.\n",
    "- Automated Deployments: CI/CD pipelines ensuring that new features and fixes are deployed seamlessly without manual intervention, increasing productivity and reliability.\n",
    "- Infrastructure Management: Using Terraform to manage and scale cloud resources efficiently, making the infrastructure agile and reproducible.\n",
    "\n",
    "### üîó Learn More & Code:\n",
    "For a detailed look into the project, challenges, and solutions, you can check out the full code and documentation here: [GitHub Repository](https://github.com/s100rab/s100rab_MLOps_DataTalks_zoomcamp/tree/main/06_best_practices_v2).\n",
    "\n",
    "This project was a fantastic opportunity to apply best practices in MLOps, ensuring that our code is robust, our infrastructure is scalable, and our deployments are automated. If you're interested in MLOps, data science, or cloud infrastructure, I'd love to connect and discuss further!\n",
    "\n",
    "#MLOps #DataScience #CloudComputing #CI/CD #InfrastructureAsCode #LocalStack #Terraform #Python #Pytest #Docker #GitHubActions #AWS\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
